{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f778f3d",
   "metadata": {},
   "source": [
    "# SAD - Synthetic Augmented Data Generator\n",
    "\n",
    "This jupyter notebook allows a quick try out of our code.\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "1) Preparation for Notebook\n",
    "\n",
    "2) Creating Synthetic Data\n",
    "\n",
    "3) Automatically augmenting real world data\n",
    "\n",
    "4) Manually augmenting real world data\n",
    "\n",
    "\n",
    "## Preparation for Notebook\n",
    "Steps that are necessary before executing this notebook:\n",
    "1) Create a virtual Python environment\n",
    "\n",
    "For Linux\n",
    "```bash\n",
    "python3 -m venv venv4datagenerator\n",
    "source venv4datagenerator/bin/activate\n",
    "```\n",
    "For Windows\n",
    "```bash\n",
    "python -m venv venv4datagenerator\n",
    "venv4datagenerator\\Scripts\\activate.bat\n",
    "```\n",
    "\n",
    "2) Install dependencies\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "3) Launch Jupyter Notebook\n",
    "```bash\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4b4b9",
   "metadata": {},
   "source": [
    "## Chunks\n",
    "\n",
    "The data generator picks the basic building blocks (chunks) from the folder `chunks` to dynamically create and annotate a ground plane. There are four different chunk types: `curve_left`, `curve_right`, `line` and `intersection`. For every chunk type there has to exist exactly one label and at least one image. If multiple images exist for one type they would be called variants of the chunk. The label contains the semantic information of the chunk. The image is the visual appearance of the road element. Every chunk type has a correspondent JSON file with its metadata. One important meta information is the ideal path that the car would take through the chunk.\n",
    "\n",
    "This figure shows how the ground plane is modularily constructed from chunks.\n",
    "<img width=\"50%\" src=\"https://user-images.githubusercontent.com/88937076/138558644-222a3bcd-ea1d-46ec-918f-5033dd79b3ef.png\"></img>\n",
    "\n",
    "In our example the chunks represent the building blocks of a miniature track for a model car. By changing the chunk images, one can adapt the data generator to their own self-driving task. The chunk images need a consistent scale and size which has to be defined in the [config](CONFIG.md). Additionally the images have to be in the bird's-eye-view.\n",
    "\n",
    "Run the following code block to see all available chunks in our demonstrator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46728e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot all available chunks.\"\"\"\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_list = glob.glob(\"./chunks/*label*.png\")\n",
    "len_list = len(labels_list)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 20))\n",
    "\n",
    "columns = 2\n",
    "rows = len_list\n",
    "for i in range(1, len_list+1):\n",
    "    label_path = labels_list[i-1]\n",
    "    img = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "    fig.add_subplot(rows, columns, 2*i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    img_path = label_path.replace(\"label\", \"nice\")\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    fig.add_subplot(rows, columns, 2*i-1)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    try:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    except:\n",
    "        print(\"Following image was not found: \" + str(img_path))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be6afb",
   "metadata": {},
   "source": [
    "## Overlays\n",
    "\n",
    "Overlays are random distracting images which the data generator puts on the camera image to enhance the variety of the dataset. They serve as disturbing artifacts and do not affect the labels of the images because they do not belong to a label class. The user can add their own overlays inside the folder `overlays`.\n",
    "\n",
    "Run the following code block to see some examples of obstacles in our demonstrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b62c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot some examples of overlays.\"\"\"\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "overlay_list = glob.glob(\"./overlays/*.png\")\n",
    "\n",
    "columns = 1\n",
    "rows = min(len(overlay_list), 5)\n",
    "\n",
    "print(\"Example of Overlays\")\n",
    "fig_overlay = plt.figure(figsize=(3, 15))\n",
    "for i in range(1, rows+1):\n",
    "    overlay_path = overlay_list[i-1]\n",
    "    img = cv2.imread(overlay_path, cv2.IMREAD_GRAYSCALE)\n",
    "    fig_overlay.add_subplot(rows, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b8453",
   "metadata": {},
   "source": [
    "## Synthetic Data Generation\n",
    "\n",
    "Run the following code to synthesize annotated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from config import Config\n",
    "import road\n",
    "import render\n",
    "from disturbances import *\n",
    "import augment\n",
    "from main import *\n",
    "from startline import Startline\n",
    "from manual_augment import ManualAugment\n",
    "config = Config(\"config1.json\", debug=False)\n",
    "\n",
    "if config[\"seed\"]:\n",
    "    random.seed(config[\"seed\"])\n",
    "    np.random.seed(config[\"seed\"])\n",
    "\n",
    "output_path_labels = config[\"paths\"][\"labels_output_path\"]\n",
    "output_path_images = config[\"paths\"][\"images_output_path\"]\n",
    "\n",
    "for name, split in config[\"splits\"].items():\n",
    "    os.makedirs(output_path_labels.format(splitname=name),\n",
    "                exist_ok=True)\n",
    "    os.makedirs(output_path_images.format(splitname=name), exist_ok=True)\n",
    "    print(\"generating split\", name)\n",
    "    print(\"synthetic\")\n",
    "    print()\n",
    "    idcs = list(range(split[\"size\"]))\n",
    "    if config[\"shuffle\"]:\n",
    "        random.shuffle(idcs)\n",
    "    generate_synthetic(\n",
    "        config,\n",
    "        name,\n",
    "        idcs[round(\n",
    "            (1 - split[\"fraction_synthetic\"]) *\n",
    "            split[\"size\"]):])\n",
    "\n",
    "    print(\"augmented\")\n",
    "    generate_augmented(\n",
    "        config,\n",
    "        name,\n",
    "        idcs[:round(\n",
    "            split[\"fraction_augmented\"] *\n",
    "            split[\"size\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03691ec2",
   "metadata": {},
   "source": [
    "## Manual Data Augmentation\n",
    "\n",
    "This repository offers an interactive GUI for manual augmentation.\n",
    "\n",
    "The class `ManualAugment` in the file `manual_augment.py` contains generic functions for manually adding overlays to annotated samples.\n",
    "The program `startline.py` shows an example of the manual augmentation. Here a start line will be added to the image and label of the data sample.\n",
    "A interactive GUI is offered to the user where he can translate and rotate the overlay inside the image.\n",
    "When the overlay has reached the final pose, the user can save the image. The overlay will be automatically added to the image and label.\n",
    "\n",
    "The start line can be moved using the following controls:\n",
    "\n",
    "\n",
    "| Key | Action |\n",
    "|-----|--------|\n",
    "| W   | move start line away from the camera  | \n",
    "| A   | move start line to the left | \n",
    "| S   | move start line towards the camera| \n",
    "| D   | move start line to the right | \n",
    "| E   | rotate the start line clockwise | \n",
    "| R   | rotate the start line counter-clockwise | \n",
    "| Q   | skip the image | \n",
    "| Space   | save the image and go to the next | \n",
    "| X   | quit | \n",
    "\n",
    "Keep in mind that the input and output paths for the images have to match.\n",
    "The paths are set in the configuration file `config1.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c866306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from config import Config\n",
    "import road\n",
    "import render\n",
    "from disturbances import *\n",
    "import augment\n",
    "from main import *\n",
    "from startline import Startline\n",
    "from manual_augment import ManualAugment\n",
    "config = Config(\"config1.json\", debug=False)\n",
    "\n",
    "\n",
    "\n",
    "startline = Startline()\n",
    "index = 0\n",
    "\n",
    "startline_img, startline_label = startline.draw_startline()\n",
    "\n",
    "labels_list = glob.glob(startline.label_input_path + \"/*.png\") if os.path.isdir(startline.label_input_path) else glob.glob(startline.label_input_path)\n",
    "images_list = glob.glob(startline.img_input_path + \"/*.png\") if os.path.isdir(startline.img_input_path) else glob.glob(startline.img_input_path)\n",
    "\n",
    "startline_img_, startline_label_ = startline.create_overlay(startline_img)\n",
    "\n",
    "if len(labels_list) == 0:\n",
    "    print(f\"no annotated images found under {self.label_input_path}\")\n",
    "\n",
    "if len(images_list) == 0:\n",
    "    print(f\"no images found under {self.img_input_path}\")\n",
    "\n",
    "exit = False\n",
    "\n",
    "for label_path, img_path in zip(labels_list, images_list):\n",
    "    if exit:\n",
    "        break\n",
    "    camera_img, camera_label = startline.import_annotated_data(\n",
    "            img_path, label_path)\n",
    "    bird_img, bird_label = startline.get_birds_eye_view(\n",
    "            camera_img, camera_label)\n",
    "\n",
    "    startline_img, startline_label = (np.copy(startline_img_),\n",
    "                                     np.copy(startline_label_))\n",
    "    key = 0\n",
    "    while key != ord(\" \") or ord(\"q\"):\n",
    "\n",
    "        startline_img, startline_label = startline.transform_image(\n",
    "                startline_img, startline_label, key)\n",
    "\n",
    "        (bird_img_n, bird_label_n,\n",
    "         camera_img_n, camera_label_n) = startline.merge_bird_overlay(\n",
    "                np.copy(startline_img), np.copy(startline_label),\n",
    "                np.copy(bird_img), np.copy(bird_label),\n",
    "                np.copy(camera_img), np.copy(camera_label))\n",
    "        key = startline.visualize_augmentation(bird_label_n, bird_img_n,\n",
    "                                               camera_img_n, camera_label_n,\n",
    "                                               index)\n",
    "\n",
    "        if key == ord(\" \"):\n",
    "            break\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        if key == ord(\"x\"):\n",
    "            exit = True\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ac7a12",
   "metadata": {},
   "source": [
    "The JSON configuration file `config1.json` is used for most of the configuration.\n",
    "The full reference is available in [CONFIG.md](CONFIG.md).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
